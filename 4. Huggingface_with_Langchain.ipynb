{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "     ------------------------------------ 268.8/268.8 kB 133.4 kB/s eta 0:00:00\n",
      "Collecting tqdm>=4.42.1\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "     -------------------------------------- 78.3/78.3 kB 290.7 kB/s eta 0:00:00\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0.1-cp37-cp37m-win_amd64.whl (153 kB)\n",
      "     ------------------------------------ 153.2/153.2 kB 760.7 kB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from huggingface_hub) (23.0)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
      "Collecting requests\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "     -------------------------------------- 62.6/62.6 kB 335.5 kB/s eta 0:00:00\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
      "     ------------------------------------ 143.0/143.0 kB 845.9 kB/s eta 0:00:00\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\2260927\\appdata\\roaming\\python\\python37\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 61.6/61.6 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "     -------------------------------------- 162.5/162.5 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
      "     ------------------------------------ 124.2/124.2 kB 662.6 kB/s eta 0:00:00\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.3.2-cp37-cp37m-win_amd64.whl (98 kB)\n",
      "     -------------------------------------- 98.1/98.1 kB 703.1 kB/s eta 0:00:00\n",
      "Installing collected packages: zipp, urllib3, typing-extensions, tqdm, pyyaml, idna, fsspec, filelock, charset-normalizer, certifi, requests, importlib-metadata, huggingface_hub\n",
      "Successfully installed certifi-2023.11.17 charset-normalizer-3.3.2 filelock-3.12.2 fsspec-2023.1.0 huggingface_hub-0.16.4 idna-3.6 importlib-metadata-6.7.0 pyyaml-6.0.1 requests-2.31.0 tqdm-4.66.1 typing-extensions-4.7.1 urllib3-2.0.7 zipp-3.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "     ---------------------------------------- 7.2/7.2 MB 5.5 MB/s eta 0:00:00\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.12.25-cp37-cp37m-win_amd64.whl (270 kB)\n",
      "     ------------------------------------ 270.2/270.2 kB 616.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (6.7.0)\n",
      "Requirement already satisfied: requests in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.1-cp37-none-win_amd64.whl (277 kB)\n",
      "     ------------------------------------ 277.7/277.7 kB 635.3 kB/s eta 0:00:00\n",
      "Collecting numpy>=1.17\n",
      "  Using cached numpy-1.21.6-cp37-cp37m-win_amd64.whl (14.0 MB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp37-cp37m-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\2260927\\appdata\\roaming\\python\\python37\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata->transformers) (3.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Installing collected packages: tokenizers, safetensors, regex, numpy, transformers\n",
      "Successfully installed numpy-1.21.6 regex-2023.12.25 safetensors-0.4.1 tokenizers-0.13.3 transformers-4.30.2\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
      "     ------------------------------------ 227.6/227.6 kB 820.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from accelerate) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\2260927\\appdata\\roaming\\python\\python37\\site-packages (from accelerate) (5.9.7)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.13.1-cp37-cp37m-win_amd64.whl (162.6 MB)\n",
      "     ---------------------------------------- 162.6/162.6 MB ? eta 0:00:00\n",
      "Requirement already satisfied: pyyaml in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from torch>=1.6.0->accelerate) (4.7.1)\n",
      "Installing collected packages: torch, accelerate\n",
      "Successfully installed accelerate-0.20.3 torch-1.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "     ------------------------------------ 105.0/105.0 MB 857.2 kB/s eta 0:00:00\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.7.3-cp37-cp37m-win_amd64.whl (34.1 MB)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in c:\\users\\2260927\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scipy->bitsandbytes) (1.21.6)\n",
      "Installing collected packages: scipy, bitsandbytes\n",
      "Successfully installed bitsandbytes-0.42.0 scipy-1.7.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install huggingface_hub\n",
    "! pip install transformers\n",
    "! pip install accelerate\n",
    "! pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 02: Import all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 03: Setting the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']=\"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tEXT2tEXT gENERATION mODELS | sEQ2sEQ mODELS | Encoder-Decoder Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"what is a good name for a company that makes {product}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sowmy\\anaconda3\\envs\\openai\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "chain=LLMChain(llm=HuggingFaceHub(repo_id='google/flan-t5-base', model_kwargs={'temperature': 0}), prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smoky'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"colourful cloaths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sowmy\\anaconda3\\envs\\openai\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "chain2 = LLMChain(llm=HuggingFaceHub(repo_id='facebook/m2m100_1.2B', model_kwargs={'temperature': 0}), prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vad är ett bra namn för ett företag som gör mobil'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2.run(\"mobile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation Models | Decoder only Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "import torch \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'google/flan-t5-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, devic\n",
    "                                              e_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = HuggingFacePipeline(pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(\n",
    "    input_variables=[\"name\"],\n",
    "    template=\"Can you tell me about footballer {name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=local_llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the name of the footballer who played for Barcelona?'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Messi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
